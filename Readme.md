# Проект "Обучение с учителем"
# Описание проекта : Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых. Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. Постройте модель с предельно большим значением F1-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте F1-меру на тестовой выборке самостоятельно. Дополнительно измеряйте AUC-ROC, сравнивайте её значение с F1-мерой.
# Что было сделано: 
# 1. Изучив данные о клиентах банка увидели, что во всех столбцах кроме Tenure нет пропусков, распределение значений в столбцах выглядит логичным. Пропуски в столбце Tenure заменили на медианное значение. Ушедших клиентов немного по сравнению с ставшимися, т.е. есть наблюдается дисбаланс классов.
# 2. Преобразовали категориальные признаки в численные, используя метод прямого кодирования One-Hot-Encodingm. Разделили исходные данные (df) на три выборки: обучающую, валидационную и тестовую, предварительно выделив признаки и целевой признак. Провели масштабирование признаков.
# 3. Для борьбы с дисбалансом классов были использованы две техники: взвешивание классов и upsampling. В каждой техники были обучены три вида моделей: логистическая регрессия, решающее дерево и случайный лес, также были замерены метрики качества каждой модели на валидационной выборке F1 - мера и AUC-ROC. По итогом обучения выбрали две модели с наилучшими показателями F1 - мера и AUC-ROC на валидационной выборке для дальнейшей проверки на тестовой выборке. Выбранные модели случайного леса: best_model_forest (F1_мера : 0.6284403669724771, AUC-ROC: 0.8539475196438401), model_forest_up (F1_мера : 0.6239669421487604, AUC-ROC :0.8528783745365022)
# 4. Проверив результаты работы моделей на тестовой выборке, получили следующие результаты: Качество работы модели "Случайный лес", которую обучали c учетом "взвешивания классов" чуть ниже, чем качество работы модели "Случайный лес", которую обучали на обучающей выборке, полученной с использованием техники upsamplin, F1_мера - 0.610 и 0.613 соответсвенно. Поэтому вибираем модель "Случайный лес", котрую обучали на обучающей выборке, полученной с использованием техники upsamplin. AUC-ROC данной модели также выше и составляет 0.856 против 0.855.
